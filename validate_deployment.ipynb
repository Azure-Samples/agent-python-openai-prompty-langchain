{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SUBSCRIPTION_ID = os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    "RESOURCE_GROUP = os.environ.get(\"AZURE_RESOURCE_GROUP\")\n",
    "AML_WORKSPACE_NAME = os.environ.get(\"AZUREAI_PROJECT_NAME\")\n",
    "ONLINE_ENDPOINT_NAME = os.environ.get(\"AZUREAI_ENDPOINT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    "    AzureCliCredential,\n",
    ")\n",
    "from azure.ai.ml import (\n",
    "    MLClient,\n",
    ")\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential(additionally_allowed_tenants=[\"*\"])\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential(additionally_allowed_tenants=[\"*\"])\n",
    "\n",
    "ml_client = MLClient(credential, SUBSCRIPTION_ID, RESOURCE_GROUP, AML_WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account set --subscription {SUBSCRIPTION_ID}\n",
    "!az configure --defaults workspace={AML_WORKSPACE_NAME} group={RESOURCE_GROUP}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    ")\n",
    "\n",
    "# get the online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=ONLINE_ENDPOINT_NAME\n",
    ")\n",
    "\n",
    "endpoint = ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langserve'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# you can customize your inference experience following Langserve instruction. The below code is just a simple example.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangserve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RemoteRunnable\n\u001b[0;32m      3\u001b[0m token \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39monline_endpoints\u001b[38;5;241m.\u001b[39mget_keys(name\u001b[38;5;241m=\u001b[39mendpoint\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mprimary_key\n\u001b[0;32m      4\u001b[0m runnable_az \u001b[38;5;241m=\u001b[39m RemoteRunnable(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;241m.\u001b[39mscoring_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mopenai-functions-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m token})\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langserve'"
     ]
    }
   ],
   "source": [
    "# you can customize your inference experience following Langserve instruction. The below code is just a simple example.\n",
    "from langserve import RemoteRunnable\n",
    "token = ml_client.online_endpoints.get_keys(name=endpoint.name).primary_key\n",
    "runnable_az = RemoteRunnable(f\"{endpoint.scoring_uri}openai-functions-agent\", headers={\"Authorization\": \"Bearer \" + token})\n",
    "async for msg in runnable_az.astream({\n",
    "    \"chat_history\": [],  \n",
    "    \"input\": \"what is the work from home policy from langchain-test-index?\"\n",
    "}):\n",
    "    print(msg, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
